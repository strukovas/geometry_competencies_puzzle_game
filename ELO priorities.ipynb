{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELO implementation with explanatory comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import math\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv file \n",
    "#path = '/Users/pedroantonio/Desktop/TFG/notebooks/anonamyze_all_data_collection_v2.csv'\n",
    "#dataEvents = pd.read_csv(path, sep=\";\")\n",
    "\n",
    "dataEvents = pd.read_csv('C:\\\\Users\\\\struk\\\\Downloads\\\\Knowledge Inference & Adaptive Learning\\\\paper\\\\anonamyze_all_data_collection.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name and number of the columns of the input file\n",
    "student_id = 'user'\n",
    "timestamp = 'initial timestamp'\n",
    "student_column_number = 1\n",
    "group_column_number = 0\n",
    "completed = 'n_completed'\n",
    "puzzle_name = 'task_id'\n",
    "puzzle_column_number = 2\n",
    "kc_column = 'kc'\n",
    "kc_column_number = 4\n",
    "\n",
    "# Different Knowledge components\n",
    "kcs = ['GMD.4', 'CO.5', 'CO.6', 'MG.1', 'MIX']\n",
    "\n",
    "# Puzzle by KC\n",
    "mg1Puzzles = ['Bird Fez', 'Pi Henge', 'Bull Market']\n",
    "gmd4Puzzles = ['Angled Silhouette', 'Not Bird', 'Stranger Shapes', 'Few Clues']\n",
    "co5Puzzles = ['45-Degree Rotations', 'Boxes Obscure Spheres', 'More Than Meets Your Eye']\n",
    "co6Puzzles = ['Tall and Small', 'Ramp Up and Can It', '6. Stretch a Ramp', '7. Max 2 Boxes']\n",
    "mixPuzzles = ['1. One Box', '2. Separated Boxes', '3. Rotate a Pyramid', '4. Match Silhouettes', '5. Removing Objects', '8. Combine 2 Ramps', '9. Scaling Round Objects', 'Square Cross-Sections', 'Pyramids are Strange', 'Object Limits', 'Square Cross-Sections', 'Pyramids are Strange', 'Object Limits', 'Tetromino', 'Warm Up', 'Sugar Cones', 'Unnecessary', 'Zzz', 'Orange Dance', 'Bear Market']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puzzle and component mapping \n",
    "typeMappingKC = {'1. One Box': 'MIX', '2. Separated Boxes': 'MIX', '3. Rotate a Pyramid': 'MIX', '4. Match Silhouettes': 'MIX', '5. Removing Objects': 'MIX', '6. Stretch a Ramp': 'CO.6', '7. Max 2 Boxes': 'CO.6', '8. Combine 2 Ramps': 'MIX', '9. Scaling Round Objects': 'MIX', \n",
    "               'Square Cross-Sections': 'MIX', 'Bird Fez': 'MG.1' , 'Pi Henge': 'MG.1', '45-Degree Rotations': 'CO.5',  'Pyramids are Strange': 'MIX', 'Boxes Obscure Spheres': 'CO.5', 'Object Limits': 'MIX', 'Tetromino': 'MIX', 'Warm Up': 'MIX', 'Angled Silhouette': 'MIX', 'Sugar Cones': 'MIX', 'Stranger Shapes': 'GMD.4', 'Tall and Small': 'CO.6', 'Ramp Up and Can It': 'CO.6', 'More Than Meets Your Eye': 'CO.5', 'Not Bird': 'GMD.4', 'Unnecessary': 'MIX', 'Zzz': 'MIX', 'Bull Market': 'MG.1', 'Few Clues': 'GMD.4', 'Orange Dance': 'MIX', 'Bear Market': 'MIX'}\n",
    "\n",
    "# Preparation data function\n",
    "def adaptedData(dataEvents, group = 'all'):\n",
    "    \n",
    "    # Sort events by time\n",
    "    dataEvents['time'] = pd.to_datetime(dataEvents['time'])\n",
    "    dataEvents = dataEvents.sort_values('time')\n",
    "    \n",
    "    #iterates in the groups and users of the data\n",
    "    dataEvents['group'] = [json.loads(x)['group'] if 'group' in json.loads(x).keys() else '' for x in dataEvents['data']]\n",
    "    dataEvents['user'] = [json.loads(x)['user'] if 'user' in json.loads(x).keys() else '' for x in dataEvents['data']]\n",
    "    dataEvents['task_id'] = [json.loads(x)['task_id'] if 'task_id' in json.loads(x).keys() else '' for x in dataEvents['data']]\n",
    "    \n",
    "    # removing those rows where we dont have a group and a user that is not guest\n",
    "    dataEvents = dataEvents[((dataEvents['group'] != '') & (dataEvents['user'] != '') & (dataEvents['user'] != 'guest'))]\n",
    "    dataEvents['group_user_id'] = dataEvents['group'] + '~' + dataEvents['user']\n",
    "    dataEvents['group_user_task_id'] = dataEvents['group'] + '~' + dataEvents['user']+'~'+dataEvents['task_id']\n",
    "\n",
    "         \n",
    "    # filtering to only take the group passed as argument\n",
    "    activity_by_user = dataEvents.groupby(['group_user_id']).agg({'id':'count',\n",
    "                                             'type':'nunique'}).reset_index().rename(columns={'id':'events',\n",
    "                                                                                              'type':'different_events'}) \n",
    "    \n",
    "    \n",
    "                                                                                              \n",
    "    #initialize the output metrics          \n",
    "    activity_by_user['active_time'] = np.nan\n",
    "    activity_by_user['n_completed'] = 0\n",
    "    activity_by_user['kc'] = ''\n",
    "    \n",
    "    # Number of user events per puzzle\n",
    "    puzzleEvents = dict()\n",
    "\n",
    "    # If the user has completed the puzzle, puzzCom = 1, if not puzzCom = 0\n",
    "    puzzCom= dict()\n",
    "    \n",
    "    # Save the competences by puzzle\n",
    "    puzzDestr = dict()\n",
    "    \n",
    "    # Number of attempts\n",
    "    n_attempts = dict()\n",
    "    # Data structure with characteristics per puzzle\n",
    "    attData = dict()\n",
    "    \n",
    "    # If the user has started the puzzle, userPuzzleInit = 1, if not userPuzzleInit = 0\n",
    "    userPuzzleInit = dict()\n",
    "    n_attemptsAux = dict()\n",
    "    \n",
    "    # Separation of users for train and test\n",
    "    userTrain = set()\n",
    "    userTest = set()\n",
    "    userTotal = set()\n",
    "    \n",
    "    # Loop by users\n",
    "    for user in dataEvents['group_user_id'].unique():\n",
    "        \n",
    "        # Computing active time\n",
    "        previousEvent = None\n",
    "        # Activity threshold in seconds \n",
    "        theresHoldActivity = 60 \n",
    "        activeTime = []\n",
    "        \n",
    "        user_events = dataEvents[dataEvents['group_user_id'] == user]\n",
    "        user_puzzle_key = None\n",
    "\n",
    "        # Loop by events\n",
    "        for enum, event in user_events.iterrows():\n",
    "            \n",
    "            # Started events\n",
    "            if(event['type'] in ['ws-start_level', 'ws-puzzle_started']):\n",
    "                \n",
    "                # Delete Sandbox\n",
    "                if(json.loads(event['data'])['task_id'] == 'Sandbox'): continue\n",
    "                \n",
    "                # key with user and puzzle\n",
    "                partialKey = event['group'] + '~' + event['user'] + '~' + json.loads(event['data'])['task_id']\n",
    "                \n",
    "                # Initialize structure with all users\n",
    "                if(event['user'] not in userTotal):\n",
    "                    userTotal.add(event['user'])\n",
    "                \n",
    "                # Initialize data structures with partial key\n",
    "                if(partialKey not in n_attemptsAux.keys()): \n",
    "                    n_attemptsAux[partialKey] = 0\n",
    "                    puzzCom[partialKey] = 0\n",
    "                    \n",
    "                # Initialize data structures with partial key. Register the first event   \n",
    "                if(partialKey not in userPuzzleInit.keys()): \n",
    "                    \n",
    "                    # First attempt\n",
    "                    n_attempts[partialKey] = 1\n",
    "                    \n",
    "                    # Complete key: group+user+puzzle+attempt\n",
    "                    user_puzzle_key = event['group'] + '~' + event['user'] + '~' + json.loads(event['data'])['task_id'] + '~' + str(n_attempts[partialKey])\n",
    "                    \n",
    "                    # The user starts the puzzle\n",
    "                    userPuzzleInit[partialKey] = 1\n",
    "                \n",
    "                # Register the event and update the key\n",
    "                else: \n",
    "                    \n",
    "                    # New event\n",
    "                    n_attempts[partialKey] += 1\n",
    "                    \n",
    "                    # Complete key: group+user+puzzle+attempt\n",
    "                    user_puzzle_key = event['group'] + '~' + event['user'] + '~' + json.loads(event['data'])['task_id'] + '~' + str(n_attempts[partialKey])\n",
    "                    \n",
    "            \n",
    "                # initialize if the id is new                                                                              \n",
    "                if(user_puzzle_key not in puzzleEvents.keys()):\n",
    "                    \n",
    "                    # Initialize:\n",
    "                    # att: Validate attempts\n",
    "                    # Completed: If the users complete the puzzle\n",
    "                    # dataCompleted: if the user data is complete\n",
    "                    # accept: The user has checked the puzzle\n",
    "                    # timestamp: Time \n",
    "                    # repeat: The user returns to the puzzle after completion\n",
    "                    attData[user_puzzle_key] = {'att': 0, 'completed': 0,'dataCompleted': 0, 'accept': 0, 'timestamp': event['time'], 'repeat':0}\n",
    "                    puzzleEvents[user_puzzle_key]= 1\n",
    "                    puzzDestr[user_puzzle_key] = ''\n",
    "                    #initialTime[user_puzzle_key] = 0\n",
    "                                        \n",
    "                # Time of first event    \n",
    "                if(event['type'] in ['ws-puzzle_started']): \n",
    "                    attData[user_puzzle_key]['timestamp'] = event['time']\n",
    "                    \n",
    "            # the event is not final event\n",
    "            if(event['type'] not in ['ws-exit_to_menu', 'ws-puzzle_complete', 'ws-create_user', 'ws-login_user']): \n",
    "                # the user is not new\n",
    "                if(user_puzzle_key in puzzleEvents.keys()):\n",
    "                    # Increase the events counter\n",
    "                    puzzleEvents[user_puzzle_key] += 1\n",
    "                    splitDes = user_puzzle_key.split(\"~\")\n",
    "                    # Records the puzzle knowledge components\n",
    "                    puzzDestr[user_puzzle_key] = typeMappingKC[splitDes[2]] \n",
    "                    # Accept flag = 1 if the user checks the solution at least once\n",
    "                    if(event['type'] == 'ws-check_solution'):\n",
    "                        attData[user_puzzle_key]['accept'] = 1\n",
    "                        \n",
    "                        \n",
    "                       \n",
    "                        \n",
    "            # the puzzle ends        \n",
    "            if(event['type'] in ['ws-exit_to_menu', 'ws-puzzle_complete', 'ws-disconnect']):\n",
    "                # the user is not new\n",
    "                if(user_puzzle_key in puzzleEvents.keys()):\n",
    "                    #the data is consistent\n",
    "                    attData[user_puzzle_key]['dataCompleted'] += 1\n",
    "                    #the data is valid\n",
    "                    if(attData[user_puzzle_key]['accept'] == 1 and attData[user_puzzle_key]['dataCompleted']==1):\n",
    "                        # Increase the attempts count\n",
    "                        n_attemptsAux[partialKey]+=1\n",
    "                        # Record the attempt number\n",
    "                        attData[user_puzzle_key]['att'] = n_attemptsAux[partialKey]\n",
    "                        #attempt after solving\n",
    "                        if(event['type'] in ['ws-puzzle_complete']):\n",
    "                            # Flag repeat = 1 if the user accesses the puzzle after solving it\n",
    "                            if(puzzCom[partialKey] !=0 and n_attemptsAux[partialKey] > 1):\n",
    "                                attData[user_puzzle_key]['repeat'] = 1\n",
    "                    # If the user solves the puzzle the first time\n",
    "                    if(event['type'] in ['ws-puzzle_complete']):\n",
    "                        if(puzzCom[partialKey] ==0):\n",
    "                            attData[user_puzzle_key]['completed'] = 1\n",
    "                            if(attData[user_puzzle_key]['accept'] == 1):\n",
    "                                puzzCom[partialKey] +=1\n",
    "    \n",
    "    # add the data by group_user_task_id            \n",
    "    for i in attData.keys(): \n",
    "        key_split = i.split('~')\n",
    "        # Train and test users\n",
    "        if(len(userTrain) < round(len(userTotal)*0.7)):\n",
    "            userTrain.add(key_split[1])\n",
    "        else: \n",
    "            if(key_split[1] not in userTrain): userTest.add(key_split[1])    \n",
    "        \n",
    "        # Data Output preparation\n",
    "        if(key_split[2] != '' and key_split[2] != 'Sandbox' and key_split[3] != '' and i != '' and key_split[1] != ''):\n",
    "            # Register the data if the nexts flags == 1\n",
    "            if(attData[i]['accept'] != 0 and attData[i]['dataCompleted'] != 0 and attData[i]['repeat'] == 0):\n",
    "                activity_by_user.at[i, 'group_user_task_att'] = key_split[0] + '~' + key_split[1] + '~' + key_split[2] + '~' + str(attData[i]['att'])\n",
    "                activity_by_user.at[i, 'group'] = key_split[0]\n",
    "                activity_by_user.at[i, 'user'] = key_split[1]\n",
    "                activity_by_user.at[i, 'task_id'] = key_split[2]\n",
    "                activity_by_user.at[i, 'attempt'] = attData[i]['att']\n",
    "                activity_by_user.at[i, 'repeat'] = attData[i]['repeat']\n",
    "                activity_by_user.at[i, 'kc'] = puzzDestr[i]\n",
    "                activity_by_user.at[i, 'n_completed'] = attData[i]['completed']\n",
    "                activity_by_user.at[i, 'initial timestamp'] = attData[i]['timestamp']\n",
    "\n",
    "    \n",
    "    #delete row with NaN\n",
    "    activity_by_user.dropna(subset = ['user'], inplace=True)\n",
    "  \n",
    "    #data output preparation             \n",
    "    activity_by_user = pd.DataFrame(activity_by_user, columns = ['group_user_task_att', 'group','user','task_id','n_completed', 'kc', 'initial timestamp'])\n",
    "\n",
    "    # Train and Test preparation per users\n",
    "    train = activity_by_user[activity_by_user['user'].isin(userTrain)]\n",
    "    test = activity_by_user[activity_by_user['user'].isin(userTest)]\n",
    "    \n",
    "    return activity_by_user, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict users: uDict\n",
    "def usersDict(datafile):\n",
    "    csv_file = datafile\n",
    "    mapUsers = {}\n",
    "    mapGroups = {}\n",
    "    cont =0\n",
    "    # Iterates and register users and groups\n",
    "    for row in csv_file.iterrows():\n",
    "        user = row[1]['user']\n",
    "        group = row[1]['group']\n",
    "        if user not in mapUsers.keys():\n",
    "            mapUsers[user]=cont\n",
    "            # Group that contains the user\n",
    "            mapGroups[user] = group\n",
    "            cont = cont+1\n",
    "    return mapUsers, mapGroups  \n",
    "\n",
    "\n",
    "# Dict puzzles: qDict\n",
    "def puzzlesDict(datafile):\n",
    "    csv_file = datafile\n",
    "    mapPuzzles = {}\n",
    "    cont =0\n",
    "    # Iterates and register the puzzles\n",
    "    for row in csv_file.iterrows():\n",
    "        question = row[1]['task_id']\n",
    "        if question not in mapPuzzles.keys():\n",
    "            mapPuzzles[question]=cont\n",
    "            cont = cont+1\n",
    "    return mapPuzzles\n",
    "\n",
    "\n",
    "\n",
    "# Dict kcs: kcDict \n",
    "def kcsDict(datafile):\n",
    "    QT = []\n",
    "    csv_file = datafile\n",
    "    mapKc = {}\n",
    "    cont =0\n",
    "    # Iterates and register the kcs\n",
    "    for row in csv_file.iterrows():\n",
    "        tags = row[1]['kc'] \n",
    "        if tags:\n",
    "            tag = tags.split(\"~\")\n",
    "            for topics in tag:\n",
    "                if topics not in mapKc.keys():\n",
    "                    mapKc[topics]=cont\n",
    "                    cont = cont + 1\n",
    "    return mapKc\n",
    "\n",
    "# Weight of the knowledge component in each puzzle\n",
    "def createKcDict(datafile):\n",
    "    \n",
    "    QTMat = dict()\n",
    "    csv_file = datafile\n",
    "    for row in csv_file.iterrows():\n",
    "        qid = row[1]['task_id']\n",
    "        kcs = row[1]['kc']\n",
    "        if(qid not in QTMat.keys()):\n",
    "            QTMat[qid]=dict()\n",
    "        if kcs:\n",
    "            kc = kcs.split(\"~\")\n",
    "            for k in kc:\n",
    "                QTMat[qid][k] =0\n",
    "\n",
    "\n",
    "    for puzzle in QTMat.keys():\n",
    "        tam = len(QTMat[puzzle])\n",
    "        if tam>0:   \n",
    "            if(puzzle in mg1Puzzles):\n",
    "                QTMat[puzzle]['MG.1'] = 1\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'MG.1'):\n",
    "                        QTMat[puzzle][x] = 0\n",
    "            elif(puzzle in gmd4Puzzles): \n",
    "                QTMat[puzzle]['GMD.4'] = 1\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'GMD.4'):\n",
    "                        QTMat[puzzle][x] = 0\n",
    "            elif(puzzle in co5Puzzles): \n",
    "                QTMat[puzzle]['CO.5'] = 1\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'CO.5'):\n",
    "                        QTMat[puzzle][x] = 0\n",
    "            elif(puzzle in co6Puzzles):  \n",
    "                QTMat[puzzle]['CO.6'] = 1\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'CO.6'):\n",
    "                        QTMat[puzzle][x] = 0\n",
    "            elif(puzzle in mixPuzzles):  \n",
    "                QTMat[puzzle]['MIX'] = 1\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'MIX'):\n",
    "                        QTMat[puzzle][x] = 0      \n",
    "            else:\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    QTMat[puzzle][x] = 1\n",
    "    return QTMat\n",
    "\n",
    "# Call the functions\n",
    "def loadDataset(datafile):\n",
    "    uDict, gDict = usersDict(datafile) \n",
    "    qDict =puzzlesDict(datafile)\n",
    "    kcDict =kcsDict(datafile)\n",
    "    kcsPuzzleDict =  createKcDict(datafile) \n",
    "\n",
    "    return uDict, gDict,qDict,kcDict, kcsPuzzleDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmseFunction(prob, ans, lenProb):\n",
    "    prob = np.array(prob)\n",
    "    ground = np.array(ans)\n",
    "    error = (prob - ans) \n",
    "    err_sqr = error*error\n",
    "    rmse = math.sqrt(err_sqr.sum()/lenProb)\n",
    "    return rmse  \n",
    "\n",
    "#Obtener un valor de accuracy basado en las predicciones de los modelos y las respuestas reales\n",
    "def accuracyFunction(ans, prob): \n",
    "    ans = np.array(ans)\n",
    "    prob = np.array(prob)\n",
    "    prob[prob >= 0.5] = 1\n",
    "    prob[prob < 0.5] = 0\n",
    "    acc = metrics.accuracy_score(ans, prob)\n",
    "    return acc\n",
    "\n",
    "def auc_roc(y, pred): \n",
    "    y = np.array(y)\n",
    "    pred = np.array(pred)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr) \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiTopic_ELO(inputData, Competency, Diff, A_count, Q_count, kcsPuzzleDict ,gDict,gamma, beta): \n",
    "\n",
    "    alpha = 1\n",
    "    alpha_denominator = 0\n",
    "    correct = 0\n",
    "    prob_test = dict()\n",
    "    ans_test = dict()  \n",
    "    userPuzzles = dict()\n",
    "    \n",
    "    completedPartialData = dict()\n",
    "\n",
    "    response = np.zeros((len(inputData), 1))\n",
    "    \n",
    "    # Main loop for input data\n",
    "    for count, (index, item) in enumerate(inputData.iterrows()):\n",
    "        \n",
    "        alpha_denominator = 0\n",
    "        # student id\n",
    "        uid = item[student_id] \n",
    "        # Puzzle name\n",
    "        qid = item[puzzle_name] \n",
    "        # initial time stamp\n",
    "        time = item[timestamp]\n",
    "            \n",
    "        # Initialize users structure    \n",
    "        if(uid not in userPuzzles.keys()): userPuzzles[uid] = []\n",
    "        userPuzzles[uid].append(qid)\n",
    "        \n",
    "        diff = dict()\n",
    "        diff[qid]=[]\n",
    "        comp= dict()\n",
    "        comp[uid]=[]\n",
    "        \n",
    "        # The student's current competence by component is multiplied by each component of the question he or she is facing. \n",
    "        # Same method for difficulty\n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            comp[uid].append(Competency[uid][k] * kcsPuzzleDict[qid][k])\n",
    "            diff[qid].append(Diff[qid][k] * kcsPuzzleDict[qid][k])\n",
    "            \n",
    "        # Adding up the competencies per component to obtain the global competence    \n",
    "        # Same method for difficulty\n",
    "        compTotal = np.sum(comp[uid])\n",
    "        diffTotal = np.sum(diff[qid])\n",
    "        \n",
    "        # With the global competition and the difficulty of the question, the probability of solving it is calculated\n",
    "        probability = (1)/(1 + math.exp( -1 * (compTotal - diffTotal)))\n",
    "        \n",
    "        # Initialize probability test structure\n",
    "        if(uid not in prob_test.keys()):\n",
    "            prob_test[uid] = dict()\n",
    "        \n",
    "        # Save the probabilities\n",
    "        prob_test[uid][qid]=probability\n",
    "        \n",
    "        # Answered puzzles count\n",
    "        q_answered_count = Q_count[qid] \n",
    "        \n",
    "        # The puzzle is completed or no\n",
    "        if item[completed] == 1:\n",
    "\n",
    "            response[count] = 1\n",
    "            correct = 1\n",
    "        else:\n",
    "            response[count] = 0\n",
    "            correct = 0\n",
    "            \n",
    "        # Initialize answers test structure\n",
    "        if(uid not in ans_test.keys()):\n",
    "            ans_test[uid] = dict()\n",
    "            \n",
    "        # Save the real result    \n",
    "        ans_test[uid][qid] = correct \n",
    "                         \n",
    "        \n",
    "        #Alpha component is calculated (normalization factor)\n",
    "        alpha_numerator = probability - correct\n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            # Competency\n",
    "            c_lambda = Competency[uid][k]\n",
    "            # Probability\n",
    "            probability_lambda = (1)/(1 + math.exp( -1 * (c_lambda - Diff[qid][k])))\n",
    "            alpha_denominator = alpha_denominator + (correct - probability_lambda)\n",
    "        alpha = abs(alpha_numerator / alpha_denominator)\n",
    "\n",
    "        \n",
    "        # Increase question and answer count\n",
    "        Q_count[qid] += 1\n",
    "        A_count[uid] += 1\n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            \n",
    "            u_answered_count = A_count[uid]\n",
    "            c = Competency[uid][k] \n",
    "            prevDiff = Diff[qid][k]\n",
    "            \n",
    "            # New key\n",
    "            key = uid+'~'+qid+'~'+k+'~'+str(round(Competency[uid][k],3)) + '~'+str(round(prevDiff,3))\n",
    "            \n",
    "            # Competency probability is calculated\n",
    "            probability = (1)/(1 + math.exp( -1 * (Competency[uid][k] - prevDiff)))\n",
    "            \n",
    "            # Update the difficulty\n",
    "            changeDiff = ((gamma)/(1 + beta * q_answered_count)) * alpha * (probability - correct)\n",
    "            Diff[qid][k] = Diff[qid][k] + kcsPuzzleDict[qid][k] * changeDiff\n",
    "                        \n",
    "            # Update the competency\n",
    "            Competency[uid][k] = Competency[uid][k]+kcsPuzzleDict[qid][k] * (gamma)/(1 + beta * u_answered_count) * alpha * (correct - probability)\n",
    "            \n",
    "            # Save the new data\n",
    "            completedPartialData[key] = {'prob': 0, 'kcs importance': 0, 'correct': -1, 'Difficulty': 0, 'Group Difficulty': 0, 'update competency': 0}\n",
    "            completedPartialData[key]['prob'] = probability\n",
    "            completedPartialData[key]['kcs importance'] = kcsPuzzleDict[qid][k]\n",
    "            completedPartialData[key]['correct'] = correct\n",
    "            completedPartialData[key]['Difficulty'] = round(Diff[qid][k],3)\n",
    "            completedPartialData[key]['timestamp'] = time\n",
    "            completedPartialData[key]['changeComp'] = kcsPuzzleDict[qid][k] * (gamma)/(1 + beta * u_answered_count) * alpha * (correct - probability)\n",
    "            completedPartialData[key]['changeDiff'] = kcsPuzzleDict[qid][k] * changeDiff\n",
    "            \n",
    "                \n",
    "    return Competency, Diff, A_count , Q_count, prob_test, ans_test, userPuzzles, completedPartialData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(output, gamma, beta):\n",
    "    \n",
    "    # Data input\n",
    "    totalData, train_set, test_set = adaptedData(dataEvents)\n",
    "    # Data structures\n",
    "    uDict,gDict,qDict,kcDict,kcsPuzzleDict = loadDataset(totalData)\n",
    "\n",
    "    competency_ELO = pd.DataFrame()\n",
    "    difficulty_ELO = pd.DataFrame()\n",
    "                                                                                              \n",
    "    #initialize the metrics       \n",
    "    difficulty_ELO['group'] = ''\n",
    "    difficulty_ELO['task_id'] = ''\n",
    "    difficulty_ELO['difficulty'] = np.nan\n",
    "    competency_ELO['group'] = ''\n",
    "    competency_ELO['user'] = ''\n",
    "    competency_ELO['kc'] = ''\n",
    "    competency_ELO['competency'] = np.nan\n",
    "    \n",
    "    \n",
    "    # Initialize idComplet with the key (group + user + kcs)\n",
    "    idComplet = dict()\n",
    "    for g in gDict.values():\n",
    "        for u in gDict.keys():\n",
    "            for k in kcs:\n",
    "                iCom = g+'~'+u+'~'+k\n",
    "                idComplet[iCom] = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    if(output == 'metrics'):\n",
    "        \n",
    "        question_counter_Model = dict() \n",
    "        for q in qDict.keys():\n",
    "            if(q not in question_counter_Model.keys()):\n",
    "                question_counter_Model[q]=dict()\n",
    "                question_counter_Model[q]=0\n",
    " \n",
    "\n",
    "\n",
    "        learner_competency_Model = dict() \n",
    "        response_counter_Model = dict()\n",
    "        for user in uDict.keys():\n",
    "            if(user not in learner_competency_Model.keys()):\n",
    "                learner_competency_Model[user]=dict()\n",
    "                response_counter_Model[user]=dict()\n",
    "                response_counter_Model[user]=0\n",
    "            for k in kcDict.keys():\n",
    "                learner_competency_Model[user][k]=0\n",
    "                \n",
    "                \n",
    "        question_difficulty = dict() \n",
    "        question_counter = dict() \n",
    "        concatedGroupTask = dict()\n",
    "        \n",
    "        # Initialize the question difficulty structure\n",
    "        for q in qDict.keys():\n",
    "            if(q not in question_difficulty.keys()):\n",
    "                question_difficulty[q]=dict()\n",
    "                question_counter[q]=dict()\n",
    "                question_counter[q]=0\n",
    "            for k in kcDict.keys():\n",
    "                question_difficulty[q][k]=0          \n",
    "\n",
    "        learner_competency_train, question_difficulty_train,response_counter_train, question_counter_train, prob_train, ans_train,userPuzzles, completedPartialData = multiTopic_ELO(train_set, learner_competency_Model,question_difficulty, response_counter_Model, question_counter_Model, kcsPuzzleDict,gDict,gamma, beta)\n",
    "        learner_competency_test, question_difficulty_test,response_counter_test, question_counter_test, prob_test, ans_test,userPuzzles, completedPartialData = multiTopic_ELO(test_set, learner_competency_train,question_difficulty_train, response_counter_train, question_counter_train, kcsPuzzleDict,gDict,gamma, beta)\n",
    "\n",
    "\n",
    "\n",
    "        # Quality metrics\n",
    "        group_prob_test = []\n",
    "        contUser =0\n",
    "        contT = 0\n",
    "        for user in prob_test.keys():\n",
    "            contUser+=1\n",
    "            for task in prob_test[user].keys():\n",
    "                contT+=1\n",
    "                group_prob_test.append(prob_test[user][task])\n",
    "\n",
    "        group_ans_test = []\n",
    "        for user in ans_test.keys():\n",
    "            for task in ans_test[user].keys():\n",
    "                group_ans_test.append(ans_test[user][task])        \n",
    "\n",
    "\n",
    "        accuracy = accuracyFunction(group_ans_test, group_prob_test)    \n",
    "        auc = auc_roc(group_ans_test, group_prob_test)\n",
    "        rmse = rmseFunction(group_prob_test, group_ans_test, len(group_prob_test))\n",
    "        \n",
    "        round_group_prob_test = [round(num) for num in group_prob_test]\n",
    "        f1 = f1_score(group_ans_test, round_group_prob_test, average='binary')\n",
    "        \n",
    "        return accuracy, auc, rmse, f1\n",
    "        \n",
    "    \n",
    "\n",
    "    if(output == 'multiTopic'):\n",
    "        \n",
    "        question_difficulty = dict() \n",
    "        question_counter = dict() \n",
    "        concatedGroupTask = dict()\n",
    "        \n",
    "        # Initialize the question difficulty structure\n",
    "        for q in qDict.keys():\n",
    "            if(q not in question_difficulty.keys()):\n",
    "                question_difficulty[q]=dict()\n",
    "                question_counter[q]=dict()\n",
    "                question_counter[q]=0\n",
    "            for k in kcDict.keys():\n",
    "                question_difficulty[q][k]=0    \n",
    "        \n",
    "        # Initialize the learner competency structure\n",
    "        learner_competency = dict()  \n",
    "        response_counter = dict() \n",
    "        for user in uDict.keys():\n",
    "            if(user not in learner_competency.keys()):\n",
    "                learner_competency[user]=dict()\n",
    "                response_counter[user]=dict()\n",
    "                response_counter[user]=0\n",
    "            for k in kcDict.keys():\n",
    "                learner_competency[user][k]=0\n",
    "\n",
    "        # Multi-ELO algorithm\n",
    "        learner_competency_train, question_difficulty_train, response_counter_train, question_counter_train, prob_train, ans_train, userPuzzles, completedPartialData = multiTopic_ELO(totalData, learner_competency, question_difficulty, response_counter, question_counter, kcsPuzzleDict,gDict,gamma, beta)\n",
    "\n",
    "    totalCompetencyGMD = []\n",
    "    totalCompetencyCO5 = []\n",
    "    totalCompetencyCO6 = []\n",
    "    totalCompetencyMG1 = []\n",
    "    totalCompetencyMIX = []\n",
    "\n",
    "    # Records the competences by KC\n",
    "    for user in learner_competency.keys():\n",
    "        for x in learner_competency[user]:\n",
    "            if(x == 'GMD.4'):\n",
    "                totalCompetencyGMD.append(learner_competency[user][x])\n",
    "            elif(x == 'CO.5'):\n",
    "                totalCompetencyCO5.append(learner_competency[user][x]) \n",
    "            elif(x == 'CO.6'):\n",
    "                totalCompetencyCO6.append(learner_competency[user][x])\n",
    "            elif(x == 'MG.1'):\n",
    "                totalCompetencyMG1.append(learner_competency[user][x])   \n",
    "            elif(x == 'MIX'):\n",
    "                totalCompetencyMIX.append(learner_competency[user][x]) \n",
    "    \n",
    "    # Min and max competence by KC\n",
    "    minCompetencyGMD = min(totalCompetencyGMD)   \n",
    "    maxCompetencyGMD = max(totalCompetencyGMD)\n",
    "    \n",
    "    minCompetencyCO5 = min(totalCompetencyCO5)   \n",
    "    maxCompetencyCO5 = max(totalCompetencyCO5)\n",
    "    \n",
    "    minCompetencyCO6 = min(totalCompetencyCO6)   \n",
    "    maxCompetencyCO6 = max(totalCompetencyCO6)\n",
    "    \n",
    "    minCompetencyMG1 = min(totalCompetencyMG1)   \n",
    "    maxCompetencyMG1 = max(totalCompetencyMG1)\n",
    "    \n",
    "    minCompetencyMIX = min(totalCompetencyMIX)   \n",
    "    maxCompetencyMIX = max(totalCompetencyMIX)\n",
    "    \n",
    "    # Normalized the competency by kc\n",
    "    normalized_learner_competency = dict()\n",
    "    normalized_global_competency = dict()\n",
    "    for user in learner_competency.keys():\n",
    "        normalized_learner_competency[user]=dict()\n",
    "        normalized_global_competency[user] = 0\n",
    "        for x in learner_competency[user]:\n",
    "            if(x == 'GMD.4'):\n",
    "                normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyGMD)/(maxCompetencyGMD-minCompetencyGMD)\n",
    "                normalized_global_competency[user] += normalized_learner_competency[user][x]\n",
    "                    \n",
    "            elif(x == 'CO.5'):\n",
    "                normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyCO5)/(maxCompetencyCO5-minCompetencyCO5)\n",
    "                normalized_global_competency[user] += normalized_learner_competency[user][x]\n",
    "              \n",
    "            elif(x == 'CO.6'):\n",
    "                normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyCO6)/(maxCompetencyCO6-minCompetencyCO6)\n",
    "                normalized_global_competency[user] += normalized_learner_competency[user][x]\n",
    "                \n",
    "            elif(x == 'MG.1'):\n",
    "                normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyMG1)/(maxCompetencyMG1-minCompetencyMG1)\n",
    "                normalized_global_competency[user] += normalized_learner_competency[user][x]\n",
    "                \n",
    "            elif(x == 'MIX'):\n",
    "                normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyMIX)/(maxCompetencyMIX-minCompetencyMIX)\n",
    "                normalized_global_competency[user] += normalized_learner_competency[user][x]\n",
    "                \n",
    "    # Global normalization        \n",
    "    for user in normalized_global_competency.keys():\n",
    "        normalized_global_competency[user] = normalized_global_competency[user]/len(kcs)\n",
    "        \n",
    "    \n",
    "    # Normalization Difficulty    \n",
    "    totalDiffGMD = []\n",
    "    totalDiffCO5 = []\n",
    "    totalDiffCO6 = []\n",
    "    totalDiffMG1 = []\n",
    "    totalDiffMIX = []\n",
    "    \n",
    "    # Records the difficulty by KC\n",
    "    for puzzle in question_difficulty.keys():\n",
    "        for x in question_difficulty[puzzle]:\n",
    "            if(x == 'GMD.4'):\n",
    "                totalDiffGMD.append(question_difficulty[puzzle][x])\n",
    "            elif(x == 'CO.5'):\n",
    "                totalDiffCO5.append(question_difficulty[puzzle][x]) \n",
    "            elif(x == 'CO.6'):\n",
    "                totalDiffCO6.append(question_difficulty[puzzle][x])\n",
    "            elif(x == 'MG.1'):\n",
    "                totalDiffMG1.append(question_difficulty[puzzle][x])    \n",
    "            elif(x == 'MIX'):\n",
    "                totalDiffMIX.append(question_difficulty[puzzle][x]) \n",
    "    \n",
    "    # Min and max difficulty by KC\n",
    "    minDiffGMD = min(totalDiffGMD)   \n",
    "    maxDiffGMD = max(totalDiffGMD)\n",
    "\n",
    "    minDiffCO5 = min(totalDiffCO5)   \n",
    "    maxDiffCO5 = max(totalDiffCO5)\n",
    "    \n",
    "    minDiffCO6 = min(totalDiffCO6)   \n",
    "    maxDiffCO6 = max(totalDiffCO6)\n",
    "    \n",
    "    minDiffMG1 = min(totalDiffMG1)   \n",
    "    maxDiffMG1 = max(totalDiffMG1)\n",
    "    \n",
    "    minDiffMIX = min(totalDiffMIX)   \n",
    "    maxDiffMIX = max(totalDiffMIX)\n",
    "    \n",
    "    normalized_question_difficulty = dict()\n",
    "    \n",
    "    # Normalized the difficulty by kc\n",
    "    for puzzle in question_difficulty.keys():\n",
    "        normalized_question_difficulty[puzzle]=dict()\n",
    "        for x in question_difficulty[puzzle]:\n",
    "            if(x == 'GMD.4'):\n",
    "                normalized_question_difficulty[puzzle][x]= (question_difficulty[puzzle][x]- minDiffGMD)/(maxDiffGMD-minDiffGMD)\n",
    "                    \n",
    "            elif(x == 'CO.5'):\n",
    "                normalized_question_difficulty[puzzle][x]= (question_difficulty[puzzle][x]- minDiffCO5)/(maxDiffCO5-minDiffCO5)\n",
    "              \n",
    "            elif(x == 'CO.6'):\n",
    "                normalized_question_difficulty[puzzle][x]= (question_difficulty[puzzle][x]- minDiffCO6)/(maxDiffCO6-minDiffCO6)\n",
    "                \n",
    "            elif(x == 'MG.1'):\n",
    "                normalized_question_difficulty[puzzle][x]= (question_difficulty[puzzle][x]- minDiffMG1)/(maxDiffMG1-minDiffMG1)\n",
    "            \n",
    "            elif(x == 'MIX'):\n",
    "                normalized_question_difficulty[puzzle][x]= (question_difficulty[puzzle][x]- minDiffMIX)/(maxDiffMIX-minDiffMIX)\n",
    "                \n",
    "    #group_prob_test = []\n",
    "    #for user in prob_test.keys():\n",
    "    #    for task in prob_test[user].keys():\n",
    "    #        group_prob_test.append(prob_test[user][task])\n",
    "            \n",
    "    #group_ans_test = []\n",
    "    #for user in ans_test.keys():\n",
    "    #    for task in ans_test[user].keys():\n",
    "    #        group_ans_test.append(ans_test[user][task])        \n",
    "                   \n",
    "    #rmse = rmseFunction(group_prob_test, group_ans_test, len(group_prob_test))\n",
    "    #auc = auc_roc(group_ans_test, group_prob_test)\n",
    "    #accuracy = accuracyFunction(group_ans_test, group_prob_test)\n",
    "    \n",
    "    # Data output preparation            \n",
    "    for i in completedPartialData.keys():\n",
    "        key_split = i.split('~')\n",
    "        competency_ELO.at[i, 'group'] = gDict[key_split[0]]    \n",
    "        competency_ELO.at[i, 'user'] = key_split[0] \n",
    "        competency_ELO.at[i, 'task_id'] = key_split[1]\n",
    "        competency_ELO.at[i, 'kc'] = key_split[2]\n",
    "        # Normalized competency by kc\n",
    "        competency_ELO.at[i, 'final_kc_competency'] = round(normalized_learner_competency[key_split[0]][key_split[2]],3)\n",
    "        # Normalized average competency\n",
    "        competency_ELO.at[i, 'final_global_competency'] = round(normalized_global_competency[key_split[0]],3)\n",
    "        # Current competency\n",
    "        competency_ELO.at[i, 'current_competency'] = key_split[3]\n",
    "        # Probability\n",
    "        competency_ELO.at[i, 'probability'] = round(completedPartialData[i]['prob'],3)\n",
    "        # If the puzzle is completed\n",
    "        competency_ELO.at[i, 'correct'] = completedPartialData[i]['correct']\n",
    "        # KC weight\n",
    "        competency_ELO.at[i, 'kcs_importance'] = round(completedPartialData[i]['kcs importance'],3)\n",
    "        # Difficulty\n",
    "        competency_ELO.at[i, 'difficulty'] = key_split[4]\n",
    "        # Time stamp\n",
    "        competency_ELO.at[i, 'timestamp'] = completedPartialData[i]['timestamp']\n",
    "        # Update competency\n",
    "        competency_ELO.at[i, 'change_competency'] = round(completedPartialData[i]['changeComp'],3)\n",
    "        # Update difficulty\n",
    "        competency_ELO.at[i, 'change_difficulty'] = round(completedPartialData[i]['changeDiff'],3)\n",
    "           \n",
    "    #data output preparation  \n",
    "    difficulty_ELO = pd.DataFrame(difficulty_ELO, columns = ['group','task_id', 'difficulty'])\n",
    "    competency_ELO = pd.DataFrame(competency_ELO, columns = ['group','user','task_id', 'timestamp','kc','kcs_importance','final_kc_competency', 'final_global_competency','current_competency','change_competency', 'probability', 'correct', 'difficulty', 'change_difficulty'])\n",
    "\n",
    "    return competency_ELO#, rmse, accuracy, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#competency_ELO = run('multiTopic',1.8, 0.05)[0]\n",
    "acc, auc, rmse, f1 = run('metrics', 1.8, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9353769676884839"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.869691056910569"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966175195143105"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
