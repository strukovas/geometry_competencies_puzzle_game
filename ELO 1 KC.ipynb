{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELO implementation with explanatory comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import math\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv file \n",
    "\n",
    "#dataEvents = pd.read_csv('C:\\\\Users\\\\struk\\\\Downloads\\\\Knowledge Inference & Adaptive Learning\\\\paper\\\\anonymized_dataset.csv', sep=\";\")\n",
    "\n",
    "dataEvents = pd.read_csv('C:\\\\Users\\\\struk\\\\Downloads\\\\Knowledge Inference & Adaptive Learning\\\\paper\\\\anonamyze_all_data_collection.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name and number of the columns of the input file\n",
    "student_id = 'user'\n",
    "timestamp = 'initial timestamp'\n",
    "student_column_number = 1\n",
    "group_column_number = 0\n",
    "completed = 'n_completed'\n",
    "puzzle_name = 'task_id'\n",
    "puzzle_column_number = 2\n",
    "kc_column = 'kc'\n",
    "kc_column_number = 4\n",
    "\n",
    "# Different Knowledge components\n",
    "kcs = ['MIX']\n",
    "\n",
    "# Puzzle by KC\n",
    "mixPuzzles = ['Tall and Small', 'Ramp Up and Can It', '6. Stretch a Ramp', '7. Max 2 Boxes', '45-Degree Rotations', 'Boxes Obscure Spheres', 'More Than Meets Your Eye', 'Angled Silhouette', 'Not Bird', 'Stranger Shapes', 'Few Clues', 'Bird Fez', 'Pi Henge', 'Bull Market', '1. One Box', '2. Separated Boxes', '3. Rotate a Pyramid', '4. Match Silhouettes', '5. Removing Objects', '8. Combine 2 Ramps', '9. Scaling Round Objects', 'Square Cross-Sections', 'Pyramids are Strange', 'Object Limits', 'Square Cross-Sections', 'Pyramids are Strange', 'Object Limits', 'Tetromino', 'Warm Up', 'Sugar Cones', 'Unnecessary', 'Zzz', 'Orange Dance', 'Bear Market']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puzzle and component mapping \n",
    "typeMappingKC = {'1. One Box': 'MIX', '2. Separated Boxes': 'MIX', '3. Rotate a Pyramid': 'MIX', '4. Match Silhouettes': 'MIX', '5. Removing Objects': 'MIX', '6. Stretch a Ramp': 'MIX', '7. Max 2 Boxes': 'MIX', '8. Combine 2 Ramps': 'MIX', '9. Scaling Round Objects': 'MIX', \n",
    "               'Square Cross-Sections': 'MIX', 'Bird Fez': 'MIX', 'Pi Henge': 'MIX', '45-Degree Rotations': 'MIX',  'Pyramids are Strange': 'MIX', 'Boxes Obscure Spheres': 'MIX', 'Object Limits': 'MIX', 'Tetromino': 'MIX', 'Warm Up': 'MIX', 'Angled Silhouette': 'MIX','Sugar Cones': 'MIX', 'Stranger Shapes': 'MIX', 'Tall and Small': 'MIX', 'Ramp Up and Can It': 'MIX', 'More Than Meets Your Eye': 'MIX', 'Not Bird': 'MIX', 'Unnecessary': 'MIX', 'Zzz': 'MIX', 'Bull Market': 'MIX', 'Few Clues': 'MIX', 'Orange Dance': 'MIX', 'Bear Market': 'MIX'}\n",
    "\n",
    "# Preparation data function\n",
    "def adaptedData(dataEvents, group = 'all'):\n",
    "    \n",
    "    # Sort events by time\n",
    "    dataEvents['time'] = pd.to_datetime(dataEvents['time'])\n",
    "    dataEvents = dataEvents.sort_values('time')\n",
    "    \n",
    "    #iterates in the groups and users of the data\n",
    "    dataEvents['group'] = [json.loads(x)['group'] if 'group' in json.loads(x).keys() else '' for x in dataEvents['data']]\n",
    "    dataEvents['user'] = [json.loads(x)['user'] if 'user' in json.loads(x).keys() else '' for x in dataEvents['data']]\n",
    "    dataEvents['task_id'] = [json.loads(x)['task_id'] if 'task_id' in json.loads(x).keys() else '' for x in dataEvents['data']]\n",
    "    \n",
    "    # removing those rows where we dont have a group and a user that is not guest\n",
    "    dataEvents = dataEvents[((dataEvents['group'] != '') & (dataEvents['user'] != '') & (dataEvents['user'] != 'guest'))]\n",
    "    dataEvents['group_user_id'] = dataEvents['group'] + '~' + dataEvents['user']\n",
    "    dataEvents['group_user_task_id'] = dataEvents['group'] + '~' + dataEvents['user']+'~'+dataEvents['task_id']\n",
    "\n",
    "         \n",
    "    # filtering to only take the group passed as argument\n",
    "    activity_by_user = dataEvents.groupby(['group_user_id']).agg({'id':'count',\n",
    "                                             'type':'nunique'}).reset_index().rename(columns={'id':'events',\n",
    "                                                                                              'type':'different_events'}) \n",
    "    \n",
    "    \n",
    "                                                                                              \n",
    "    #initialize the output metrics          \n",
    "    activity_by_user['active_time'] = np.nan\n",
    "    activity_by_user['n_completed'] = 0\n",
    "    activity_by_user['kc'] = ''\n",
    "    \n",
    "    # Number of user events per puzzle\n",
    "    puzzleEvents = dict()\n",
    "\n",
    "    # If the user has completed the puzzle, puzzCom = 1, if not puzzCom = 0\n",
    "    puzzCom= dict()\n",
    "    \n",
    "    # Save the competences by puzzle\n",
    "    puzzDestr = dict()\n",
    "    \n",
    "    # Number of attempts\n",
    "    n_attempts = dict()\n",
    "    # Data structure with characteristics per puzzle\n",
    "    attData = dict()\n",
    "    \n",
    "    # If the user has started the puzzle, userPuzzleInit = 1, if not userPuzzleInit = 0\n",
    "    userPuzzleInit = dict()\n",
    "    n_attemptsAux = dict()\n",
    "    \n",
    "    # Separation of users for train and test\n",
    "    userTrain = set()\n",
    "    userTest = set()\n",
    "    userTotal = set()\n",
    "    \n",
    "    # Loop by users\n",
    "    for user in dataEvents['group_user_id'].unique():\n",
    "        \n",
    "        # Computing active time\n",
    "        previousEvent = None\n",
    "        # Activity threshold in seconds \n",
    "        theresHoldActivity = 60 \n",
    "        activeTime = []\n",
    "        \n",
    "        user_events = dataEvents[dataEvents['group_user_id'] == user]\n",
    "        user_puzzle_key = None\n",
    "\n",
    "        # Loop by events\n",
    "        for enum, event in user_events.iterrows():\n",
    "            \n",
    "            # Started events\n",
    "            if(event['type'] in ['ws-start_level', 'ws-puzzle_started']):\n",
    "                \n",
    "                # Delete Sandbox\n",
    "                if(json.loads(event['data'])['task_id'] == 'Sandbox'): continue\n",
    "                \n",
    "                # key with user and puzzle\n",
    "                partialKey = event['group'] + '~' + event['user'] + '~' + json.loads(event['data'])['task_id']\n",
    "                \n",
    "                # Initialize structure with all users\n",
    "                if(event['user'] not in userTotal):\n",
    "                    userTotal.add(event['user'])\n",
    "                \n",
    "                # Initialize data structures with partial key\n",
    "                if(partialKey not in n_attemptsAux.keys()): \n",
    "                    n_attemptsAux[partialKey] = 0\n",
    "                    puzzCom[partialKey] = 0\n",
    "                    \n",
    "                # Initialize data structures with partial key. Register the first event   \n",
    "                if(partialKey not in userPuzzleInit.keys()): \n",
    "                    \n",
    "                    # First attempt\n",
    "                    n_attempts[partialKey] = 1\n",
    "                    \n",
    "                    # Complete key: group+user+puzzle+attempt\n",
    "                    user_puzzle_key = event['group'] + '~' + event['user'] + '~' + json.loads(event['data'])['task_id'] + '~' + str(n_attempts[partialKey])\n",
    "                    \n",
    "                    # The user starts the puzzle\n",
    "                    userPuzzleInit[partialKey] = 1\n",
    "                \n",
    "                # Register the event and update the key\n",
    "                else: \n",
    "                    \n",
    "                    # New event\n",
    "                    n_attempts[partialKey] += 1\n",
    "                    \n",
    "                    # Complete key: group+user+puzzle+attempt\n",
    "                    user_puzzle_key = event['group'] + '~' + event['user'] + '~' + json.loads(event['data'])['task_id'] + '~' + str(n_attempts[partialKey])\n",
    "                    \n",
    "            \n",
    "                # initialize if the id is new                                                                              \n",
    "                if(user_puzzle_key not in puzzleEvents.keys()):\n",
    "                    \n",
    "                    # Initialize:\n",
    "                    # att: Validate attempts\n",
    "                    # Completed: If the users complete the puzzle\n",
    "                    # dataCompleted: if the user data is complete\n",
    "                    # accept: The user has checked the puzzle\n",
    "                    # timestamp: Time \n",
    "                    # repeat: The user returns to the puzzle after completion\n",
    "                    attData[user_puzzle_key] = {'att': 0, 'completed': 0,'dataCompleted': 0, 'accept': 0, 'timestamp': event['time'], 'repeat':0}\n",
    "                    puzzleEvents[user_puzzle_key]= 1\n",
    "                    puzzDestr[user_puzzle_key] = ''\n",
    "                    #initialTime[user_puzzle_key] = 0\n",
    "                                        \n",
    "                # Time of first event    \n",
    "                if(event['type'] in ['ws-puzzle_started']): \n",
    "                    attData[user_puzzle_key]['timestamp'] = event['time']\n",
    "                    \n",
    "            # the event is not final event\n",
    "            if(event['type'] not in ['ws-exit_to_menu', 'ws-puzzle_complete', 'ws-create_user', 'ws-login_user']): \n",
    "                # the user is not new\n",
    "                if(user_puzzle_key in puzzleEvents.keys()):\n",
    "                    # Increase the events counter\n",
    "                    puzzleEvents[user_puzzle_key] += 1\n",
    "                    splitDes = user_puzzle_key.split(\"~\")\n",
    "                    # Records the puzzle knowledge components\n",
    "                    puzzDestr[user_puzzle_key] = typeMappingKC[splitDes[2]] \n",
    "                    # Accept flag = 1 if the user checks the solution at least once\n",
    "                    if(event['type'] == 'ws-check_solution'):\n",
    "                        attData[user_puzzle_key]['accept'] = 1\n",
    "                        \n",
    "                        \n",
    "                       \n",
    "                        \n",
    "            # the puzzle ends        \n",
    "            if(event['type'] in ['ws-exit_to_menu', 'ws-puzzle_complete', 'ws-disconnect']):\n",
    "                # the user is not new\n",
    "                if(user_puzzle_key in puzzleEvents.keys()):\n",
    "                    #the data is consistent\n",
    "                    attData[user_puzzle_key]['dataCompleted'] += 1\n",
    "                    #the data is valid\n",
    "                    if(attData[user_puzzle_key]['accept'] == 1 and attData[user_puzzle_key]['dataCompleted']==1):\n",
    "                        # Increase the attempts count\n",
    "                        n_attemptsAux[partialKey]+=1\n",
    "                        # Record the attempt number\n",
    "                        attData[user_puzzle_key]['att'] = n_attemptsAux[partialKey]\n",
    "                        #attempt after solving\n",
    "                        if(event['type'] in ['ws-puzzle_complete']):\n",
    "                            # Flag repeat = 1 if the user accesses the puzzle after solving it\n",
    "                            if(puzzCom[partialKey] !=0 and n_attemptsAux[partialKey] > 1):\n",
    "                                attData[user_puzzle_key]['repeat'] = 1\n",
    "                    # If the user solves the puzzle the first time\n",
    "                    if(event['type'] in ['ws-puzzle_complete']):\n",
    "                        if(puzzCom[partialKey] ==0):\n",
    "                            attData[user_puzzle_key]['completed'] = 1\n",
    "                            if(attData[user_puzzle_key]['accept'] == 1):\n",
    "                                puzzCom[partialKey] +=1\n",
    "    \n",
    "    # add the data by group_user_task_id            \n",
    "    for i in attData.keys(): \n",
    "        key_split = i.split('~')\n",
    "        # Train and test users\n",
    "        if(len(userTrain) < round(len(userTotal)*0.7)):\n",
    "            userTrain.add(key_split[1])\n",
    "        else: \n",
    "            if(key_split[1] not in userTrain): userTest.add(key_split[1])    \n",
    "        \n",
    "        # Data Output preparation\n",
    "        if(key_split[2] != '' and key_split[2] != 'Sandbox' and key_split[3] != '' and i != '' and key_split[1] != ''):\n",
    "            # Register the data if the nexts flags == 1\n",
    "            if(attData[i]['accept'] != 0 and attData[i]['dataCompleted'] != 0 and attData[i]['repeat'] == 0):\n",
    "                activity_by_user.at[i, 'group_user_task_att'] = key_split[0] + '~' + key_split[1] + '~' + key_split[2] + '~' + str(attData[i]['att'])\n",
    "                activity_by_user.at[i, 'group'] = key_split[0]\n",
    "                activity_by_user.at[i, 'user'] = key_split[1]\n",
    "                activity_by_user.at[i, 'task_id'] = key_split[2]\n",
    "                activity_by_user.at[i, 'attempt'] = attData[i]['att']\n",
    "                activity_by_user.at[i, 'repeat'] = attData[i]['repeat']\n",
    "                activity_by_user.at[i, 'kc'] = puzzDestr[i]\n",
    "                activity_by_user.at[i, 'n_completed'] = attData[i]['completed']\n",
    "                activity_by_user.at[i, 'initial timestamp'] = attData[i]['timestamp']\n",
    "    \n",
    "    #delete row with NaN\n",
    "    activity_by_user.dropna(subset = ['user'], inplace=True)\n",
    "    \n",
    "    #data output preparation             \n",
    "    activity_by_user = pd.DataFrame(activity_by_user, columns = ['group_user_task_att', 'group','user','task_id','n_completed', 'kc', 'initial timestamp'])\n",
    "    \n",
    "    # Train and Test preparation per users\n",
    "    train = activity_by_user[activity_by_user['user'].isin(userTrain)]\n",
    "    test = activity_by_user[activity_by_user['user'].isin(userTest)]\n",
    "    \n",
    "    return activity_by_user, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict users: uDict\n",
    "def usersDict(datafile):\n",
    "    csv_file = datafile\n",
    "    mapUsers = {}\n",
    "    mapGroups = {}\n",
    "    cont =0\n",
    "    puzzles_count = dict()\n",
    "    \n",
    "    # Iterates and register users and groups\n",
    "    for row in csv_file.iterrows():\n",
    "        user = row[1]['user']\n",
    "        group = row[1]['group']\n",
    "        puzzle = row[1]['task_id']\n",
    "        if puzzle not in puzzles_count:\n",
    "            puzzles_count[puzzle] = 1\n",
    "        else:\n",
    "            puzzles_count[puzzle]+= 1\n",
    "        if user not in mapUsers.keys():\n",
    "            mapUsers[user]=cont\n",
    "            # Group that contains the user\n",
    "            mapGroups[user] = group\n",
    "            cont = cont+1\n",
    "    print(puzzles_count)\n",
    "    return mapUsers, mapGroups  \n",
    "\n",
    "\n",
    "# Dict puzzles: qDict\n",
    "def puzzlesDict(datafile):\n",
    "    csv_file = datafile\n",
    "    mapPuzzles = {}\n",
    "    cont =0\n",
    "    # Iterates and register the puzzles\n",
    "    for row in csv_file.iterrows():\n",
    "        question = row[1]['task_id']\n",
    "        if question not in mapPuzzles.keys():\n",
    "            mapPuzzles[question]=cont\n",
    "            cont = cont+1\n",
    "    return mapPuzzles\n",
    "\n",
    "\n",
    "\n",
    "# Dict kcs: kcDict \n",
    "def kcsDict(datafile):\n",
    "    QT = []\n",
    "    csv_file = datafile\n",
    "    mapKc = {}\n",
    "    cont =0\n",
    "    # Iterates and register the kcs\n",
    "    for row in csv_file.iterrows():\n",
    "        tags = row[1]['kc'] \n",
    "        if tags:\n",
    "            tag = tags.split(\"~\")\n",
    "            for topics in tag:\n",
    "                if topics not in mapKc.keys():\n",
    "                    mapKc[topics]=cont\n",
    "                    cont = cont + 1\n",
    "    return mapKc\n",
    "\n",
    "# Weight of the knowledge component in each puzzle\n",
    "def createKcDict(datafile):\n",
    "    \n",
    "    QTMat = dict()\n",
    "    csv_file = datafile\n",
    "    for row in csv_file.iterrows():\n",
    "        qid = row[1]['task_id']\n",
    "        kcs = row[1]['kc']\n",
    "        if(qid not in QTMat.keys()):\n",
    "            QTMat[qid]=dict()\n",
    "        if kcs:\n",
    "            kc = kcs.split(\"~\")\n",
    "            for k in kc:\n",
    "                QTMat[qid][k] =0\n",
    "\n",
    "\n",
    "    for puzzle in QTMat.keys():\n",
    "        tam = len(QTMat[puzzle])\n",
    "        if tam>0:           \n",
    "            if(puzzle in mixPuzzles):  \n",
    "                QTMat[puzzle]['MIX'] = 1\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'MIX'):\n",
    "                        QTMat[puzzle][x] = 0\n",
    "            else:\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    QTMat[puzzle][x] = 1\n",
    "    return QTMat\n",
    "\n",
    "# Call the functions\n",
    "def loadDataset(datafile):\n",
    "    uDict, gDict = usersDict(datafile) \n",
    "    qDict =puzzlesDict(datafile)\n",
    "    kcDict =kcsDict(datafile)\n",
    "    kcsPuzzleDict =  createKcDict(datafile) \n",
    "\n",
    "    return uDict, gDict,qDict,kcDict, kcsPuzzleDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmseFunction(prob, ans, lenProb):\n",
    "    prob = np.array(prob)\n",
    "    ground = np.array(ans)\n",
    "    error = (prob - ans) \n",
    "    err_sqr = error*error\n",
    "    rmse = math.sqrt(err_sqr.sum()/lenProb)\n",
    "    return rmse  \n",
    "\n",
    "#Obtener un valor de accuracy basado en las predicciones de los modelos y las respuestas reales\n",
    "def accuracyFunction(ans, prob): \n",
    "    ans = np.array(ans)\n",
    "    prob = np.array(prob)\n",
    "    prob[prob >= 0.5] = 1\n",
    "    prob[prob < 0.5] = 0\n",
    "    acc = metrics.accuracy_score(ans, prob)\n",
    "    return acc\n",
    "\n",
    "def auc_roc(y, pred): \n",
    "    y = np.array(y)\n",
    "    pred = np.array(pred)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr) \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiTopic_ELO(inputData, Competency, Diff, A_count, Q_count, kcsPuzzleDict ,gDict,gamma, beta): \n",
    "\n",
    "    alpha = 1\n",
    "    alpha_denominator = 0\n",
    "    correct = 0\n",
    "    prob_test = dict()\n",
    "    ans_test = dict()  \n",
    "    userPuzzles = dict()\n",
    "    \n",
    "    completedPartialData = dict()\n",
    "\n",
    "    response = np.zeros((len(inputData), 1))\n",
    "    \n",
    "    # Main loop for input data\n",
    "    for count, (index, item) in enumerate(inputData.iterrows()):\n",
    "        \n",
    "        alpha_denominator = 0\n",
    "        # student id\n",
    "        uid = item[student_id] \n",
    "        # Puzzle name\n",
    "        qid = item[puzzle_name] \n",
    "        # initial time stamp\n",
    "        time = item[timestamp]\n",
    "            \n",
    "        # Initialize users structure    \n",
    "        if(uid not in userPuzzles.keys()): userPuzzles[uid] = []\n",
    "        userPuzzles[uid].append(qid)\n",
    "        \n",
    "        diff = dict()\n",
    "        diff[qid]=[]\n",
    "        comp= dict()\n",
    "        comp[uid]=[]\n",
    "        \n",
    "        # The student's current competence by component is multiplied by each component of the question he or she is facing. \n",
    "        # Same method for difficulty\n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            comp[uid].append(Competency[uid][k] * kcsPuzzleDict[qid][k])\n",
    "            diff[qid].append(Diff[qid][k] * kcsPuzzleDict[qid][k])\n",
    "            \n",
    "        # Adding up the competencies per component to obtain the global competence    \n",
    "        # Same method for difficulty\n",
    "        compTotal = np.sum(comp[uid])\n",
    "        diffTotal = np.sum(diff[qid])\n",
    "        \n",
    "        # With the global competition and the difficulty of the question, the probability of solving it is calculated\n",
    "        probability = (1)/(1 + math.exp( -1 * (compTotal - diffTotal)))\n",
    "        \n",
    "        # Initialize probability test structure\n",
    "        if(uid not in prob_test.keys()):\n",
    "            prob_test[uid] = dict()\n",
    "        \n",
    "        # Save the probabilities\n",
    "        prob_test[uid][qid]=probability\n",
    "        \n",
    "        # Answered puzzles count\n",
    "        q_answered_count = Q_count[qid] \n",
    "        \n",
    "        # The puzzle is completed or no\n",
    "        if item[completed] == 1:\n",
    "\n",
    "            response[count] = 1\n",
    "            correct = 1\n",
    "        else:\n",
    "            response[count] = 0\n",
    "            correct = 0\n",
    "            \n",
    "        # Initialize answers test structure\n",
    "        if(uid not in ans_test.keys()):\n",
    "            ans_test[uid] = dict()\n",
    "            \n",
    "        # Save the real result    \n",
    "        ans_test[uid][qid] = correct \n",
    "                         \n",
    "        \n",
    "        #Alpha component is calculated (normalization factor)\n",
    "        alpha_numerator = probability - correct\n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            # Competency\n",
    "            c_lambda = Competency[uid][k]\n",
    "            # Probability\n",
    "            probability_lambda = (1)/(1 + math.exp( -1 * (c_lambda - Diff[qid][k])))\n",
    "            alpha_denominator = alpha_denominator + (correct - probability_lambda)\n",
    "        alpha = abs(alpha_numerator / alpha_denominator)\n",
    "\n",
    "        \n",
    "        # Increase question and answer count\n",
    "        Q_count[qid] += 1\n",
    "        A_count[uid] += 1\n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            \n",
    "            u_answered_count = A_count[uid]\n",
    "            c = Competency[uid][k] \n",
    "            prevDiff = Diff[qid][k]\n",
    "            \n",
    "            # New key\n",
    "            key = uid+'~'+qid+'~'+k+'~'+str(round(Competency[uid][k],3)) + '~'+str(round(prevDiff,3))\n",
    "            \n",
    "            # Competency probability is calculated\n",
    "            probability = (1)/(1 + math.exp( -1 * (Competency[uid][k] - prevDiff)))\n",
    "            \n",
    "            # Update the difficulty\n",
    "            changeDiff = ((gamma)/(1 + beta * q_answered_count)) * alpha * (probability - correct)\n",
    "            Diff[qid][k] = Diff[qid][k] + kcsPuzzleDict[qid][k] * changeDiff\n",
    "                        \n",
    "            # Update the competency\n",
    "            Competency[uid][k] = Competency[uid][k]+kcsPuzzleDict[qid][k] * (gamma)/(1 + beta * u_answered_count) * alpha * (correct - probability)\n",
    "            \n",
    "            # Save the new data\n",
    "            completedPartialData[key] = {'prob': 0, 'kcs importance': 0, 'correct': -1, 'Difficulty': 0, 'Group Difficulty': 0, 'update competency': 0}\n",
    "            completedPartialData[key]['prob'] = probability\n",
    "            completedPartialData[key]['kcs importance'] = kcsPuzzleDict[qid][k]\n",
    "            completedPartialData[key]['correct'] = correct\n",
    "            completedPartialData[key]['Difficulty'] = round(Diff[qid][k],3)\n",
    "            completedPartialData[key]['timestamp'] = time\n",
    "            completedPartialData[key]['changeComp'] = kcsPuzzleDict[qid][k] * (gamma)/(1 + beta * u_answered_count) * alpha * (correct - probability)\n",
    "            completedPartialData[key]['changeDiff'] = kcsPuzzleDict[qid][k] * changeDiff\n",
    "            \n",
    "                \n",
    "    return Competency, Diff, A_count , Q_count, prob_test, ans_test, userPuzzles, completedPartialData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(output, gamma, beta):\n",
    "    \n",
    "    # Data input\n",
    "    totalData, train_set, test_set = adaptedData(dataEvents)\n",
    "    # Data structures\n",
    "    uDict,gDict,qDict,kcDict,kcsPuzzleDict = loadDataset(totalData)\n",
    "\n",
    "    competency_ELO = pd.DataFrame()\n",
    "    difficulty_ELO = pd.DataFrame()\n",
    "                                                                                              \n",
    "    #initialize the metrics       \n",
    "    difficulty_ELO['group'] = ''\n",
    "    difficulty_ELO['task_id'] = ''\n",
    "    difficulty_ELO['difficulty'] = np.nan\n",
    "    competency_ELO['group'] = ''\n",
    "    competency_ELO['user'] = ''\n",
    "    competency_ELO['kc'] = ''\n",
    "    competency_ELO['competency'] = np.nan\n",
    "    \n",
    "    \n",
    "    # Initialize idComplet with the key (group + user + kcs)\n",
    "    idComplet = dict()\n",
    "    for g in gDict.values():\n",
    "        for u in gDict.keys():\n",
    "            for k in kcs:\n",
    "                iCom = g+'~'+u+'~'+k\n",
    "                idComplet[iCom] = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    if(output == 'metrics'):\n",
    "        \n",
    "        question_counter_Model = dict() \n",
    "        for q in qDict.keys():\n",
    "            if(q not in question_counter_Model.keys()):\n",
    "                question_counter_Model[q]=dict()\n",
    "                question_counter_Model[q]=0\n",
    " \n",
    "\n",
    "\n",
    "        learner_competency_Model = dict() \n",
    "        response_counter_Model = dict()\n",
    "        for user in uDict.keys():\n",
    "            if(user not in learner_competency_Model.keys()):\n",
    "                learner_competency_Model[user]=dict()\n",
    "                response_counter_Model[user]=dict()\n",
    "                response_counter_Model[user]=0\n",
    "            for k in kcDict.keys():\n",
    "                learner_competency_Model[user][k]=0\n",
    "                \n",
    "                \n",
    "        question_difficulty = dict() \n",
    "        question_counter = dict() \n",
    "        concatedGroupTask = dict()\n",
    "        \n",
    "        # Initialize the question difficulty structure\n",
    "        for q in qDict.keys():\n",
    "            if(q not in question_difficulty.keys()):\n",
    "                question_difficulty[q]=dict()\n",
    "                question_counter[q]=dict()\n",
    "                question_counter[q]=0\n",
    "            for k in kcDict.keys():\n",
    "                question_difficulty[q][k]=0          \n",
    "\n",
    "        learner_competency_train, question_difficulty_train,response_counter_train, question_counter_train, prob_train, ans_train,userPuzzles, completedPartialData = multiTopic_ELO(train_set, learner_competency_Model,question_difficulty, response_counter_Model, question_counter_Model, kcsPuzzleDict,gDict,gamma, beta)\n",
    "        \n",
    "        def new_df_puzzles(test_set, puzzle):\n",
    "            test_set_new = []\n",
    "            for index, row in test_set.iterrows():\n",
    "                if row['task_id'] == puzzle:\n",
    "                    test_set_new.append([row[\"group_user_task_att\"], row[\"group\"], row[\"user\"], row[\"task_id\"], row[\"n_completed\"], row[\"kc\"], row[\"initial timestamp\"]])\n",
    "            return pd.DataFrame(test_set_new, columns = ['group_user_task_att', 'group', 'user', 'task_id', 'n_completed', 'kc', 'initial timestamp'])\n",
    "\n",
    "        users_all = dict()\n",
    "        \n",
    "        def record_users(test_set):\n",
    "            for index, row in test_set.iterrows():\n",
    "                if row['user'] not in users_all:\n",
    "                    users_all[row[\"user\"]] = 1\n",
    "                else:\n",
    "                    users_all[row[\"user\"]] += 1\n",
    "            return users_all\n",
    "        \n",
    "        def new_df_users(test_set, user):\n",
    "            test_set_new = []\n",
    "            for index, row in test_set.iterrows():\n",
    "                if row['user'] == user:\n",
    "                    #print('CORRECT')\n",
    "                    #print(puzzle)\n",
    "                    test_set_new.append([row[\"group_user_task_att\"], row[\"group\"], row[\"user\"], row[\"task_id\"], row[\"n_completed\"], row[\"kc\"], row[\"initial timestamp\"]])\n",
    "                #else:\n",
    "                    #print('ERROR')\n",
    "                    #print(row['task_id'])\n",
    "            return pd.DataFrame(test_set_new, columns = ['group_user_task_att', 'group', 'user', 'task_id', 'n_completed', 'kc', 'initial timestamp'])\n",
    "\n",
    "        \n",
    "        users_all = record_users(test_set)\n",
    "        \n",
    "        acc_per_user = dict()\n",
    "        acc_per_puzzle = dict()\n",
    "    \n",
    "        for user in users_all:\n",
    "            test_set2 = new_df_users(test_set, user)\n",
    "        \n",
    "        #for puzzle in mixPuzzles:\n",
    "            #test_set2 = new_df_puzzles(test_set, puzzle)\n",
    "            \n",
    "            learner_competency_test, question_difficulty_test,response_counter_test, question_counter_test, prob_test, ans_test,userPuzzles, completedPartialData = multiTopic_ELO(test_set2, learner_competency_train,question_difficulty_train, response_counter_train, question_counter_train, kcsPuzzleDict,gDict,gamma, beta)\n",
    "\n",
    "            \n",
    "            # Quality metrics\n",
    "            group_prob_test = []\n",
    "            contUser =0\n",
    "            contT = 0\n",
    "            for user in prob_test.keys():\n",
    "                contUser+=1\n",
    "                for task in prob_test[user].keys():\n",
    "                    contT+=1\n",
    "                    group_prob_test.append(prob_test[user][task])\n",
    "\n",
    "            group_ans_test = []\n",
    "            for user in ans_test.keys():\n",
    "                for task in ans_test[user].keys():\n",
    "                    group_ans_test.append(ans_test[user][task])        \n",
    "\n",
    "\n",
    "            accuracy = accuracyFunction(group_ans_test, group_prob_test)    \n",
    "            #auc = auc_roc(group_ans_test, group_prob_test)\n",
    "            #rmse = rmseFunction(group_prob_test, group_ans_test, len(group_prob_test))\n",
    "            #round_group_prob_test = [round(num) for num in group_prob_test]\n",
    "            #f1 = f1_score(group_ans_test, round_group_prob_test, average='binary')\n",
    "        \n",
    "            acc_per_user[user]=accuracy\n",
    "            #acc_per_puzzle[puzzle]= accuracy\n",
    "            \n",
    "        print('____')\n",
    "        print(acc_per_user)\n",
    "        \n",
    "        return acc_per_user#, acc_per_puzzle#, accuracy, auc, rmse, f1, \n",
    "        \n",
    "    \n",
    "\n",
    "    if(output == 'multiTopic'):\n",
    "        \n",
    "        question_difficulty = dict() \n",
    "        question_counter = dict() \n",
    "        concatedGroupTask = dict()\n",
    "        \n",
    "        # Initialize the question difficulty structure\n",
    "        for q in qDict.keys():\n",
    "            if(q not in question_difficulty.keys()):\n",
    "                question_difficulty[q]=dict()\n",
    "                question_counter[q]=dict()\n",
    "                question_counter[q]=0\n",
    "            for k in kcDict.keys():\n",
    "                question_difficulty[q][k]=0    \n",
    "        \n",
    "        # Initialize the learner competency structure\n",
    "        learner_competency = dict()  \n",
    "        response_counter = dict() \n",
    "        for user in uDict.keys():\n",
    "            if(user not in learner_competency.keys()):\n",
    "                learner_competency[user]=dict()\n",
    "                response_counter[user]=dict()\n",
    "                response_counter[user]=0\n",
    "            for k in kcDict.keys():\n",
    "                learner_competency[user][k]=0\n",
    "\n",
    "        # Multi-ELO algorithm\n",
    "        learner_competency_train, question_difficulty_train, response_counter_train, question_counter_train, prob_train, ans_train, userPuzzles, completedPartialData = multiTopic_ELO(totalData, learner_competency, question_difficulty, response_counter, question_counter, kcsPuzzleDict,gDict,gamma, beta)\n",
    "\n",
    "    totalCompetencyGMD = []\n",
    "    totalCompetencyCO5 = []\n",
    "    totalCompetencyCO6 = []\n",
    "    totalCompetencyMG1 = []\n",
    "    totalCompetencyMIX = []\n",
    "\n",
    "    # Records the competences by KC\n",
    "    for user in learner_competency.keys():\n",
    "        for x in learner_competency[user]:\n",
    "            if(x == 'MIX'):\n",
    "                totalCompetencyMIX.append(learner_competency[user][x]) \n",
    "    \n",
    "    # Min and max competence by KC\n",
    "    \n",
    "    minCompetencyMIX = min(totalCompetencyMIX)   \n",
    "    maxCompetencyMIX = max(totalCompetencyMIX)\n",
    "    \n",
    "    # Normalized the competency by kc\n",
    "    normalized_learner_competency = dict()\n",
    "    normalized_global_competency = dict()\n",
    "    for user in learner_competency.keys():\n",
    "        normalized_learner_competency[user]=dict()\n",
    "        normalized_global_competency[user] = 0\n",
    "        for x in learner_competency[user]:     \n",
    "            if(x == 'MIX'):\n",
    "                normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyMIX)/(maxCompetencyMIX-minCompetencyMIX)\n",
    "                normalized_global_competency[user] += normalized_learner_competency[user][x]\n",
    "                \n",
    "    # Global normalization        \n",
    "    for user in normalized_global_competency.keys():\n",
    "        normalized_global_competency[user] = normalized_global_competency[user]/len(kcs)\n",
    "        \n",
    "    \n",
    "    # Normalization Difficulty    \n",
    "    totalDiffGMD = []\n",
    "    totalDiffCO5 = []\n",
    "    totalDiffCO6 = []\n",
    "    totalDiffMG1 = []\n",
    "    totalDiffMIX = []\n",
    "        \n",
    "    # Records the difficulty by KC\n",
    "    for puzzle in question_difficulty.keys():\n",
    "        for x in question_difficulty[puzzle]:\n",
    "            if(x == 'MIX'):\n",
    "                totalDiffMIX.append(question_difficulty[puzzle][x]) \n",
    "    \n",
    "    # Min and max difficulty by KC\n",
    "    \n",
    "    minDiffMIX = min(totalDiffMIX)   \n",
    "    maxDiffMIX = max(totalDiffMIX)\n",
    "    \n",
    "    normalized_question_difficulty = dict()\n",
    "    \n",
    "    # Normalized the difficulty by kc\n",
    "    for puzzle in question_difficulty.keys():\n",
    "        normalized_question_difficulty[puzzle]=dict()\n",
    "        for x in question_difficulty[puzzle]:\n",
    "            if(x == 'MIX'):\n",
    "                normalized_question_difficulty[puzzle][x]= (question_difficulty[puzzle][x]- minDiffMIX)/(maxDiffMIX-minDiffMIX)\n",
    "        \n",
    "    #group_prob_test = []\n",
    "    #for user in prob_test.keys():\n",
    "    #    for task in prob_test[user].keys():\n",
    "    #        group_prob_test.append(prob_test[user][task])\n",
    "            \n",
    "    #group_ans_test = []\n",
    "    #for user in ans_test.keys():\n",
    "    #    for task in ans_test[user].keys():\n",
    "    #        group_ans_test.append(ans_test[user][task])        \n",
    "                   \n",
    "    #rmse = rmseFunction(group_prob_test, group_ans_test, len(group_prob_test))\n",
    "    #auc = auc_roc(group_ans_test, group_prob_test)\n",
    "    #accuracy = accuracyFunction(group_ans_test, group_prob_test)\n",
    "    \n",
    "    # Data output preparation            \n",
    "    for i in completedPartialData.keys():\n",
    "        key_split = i.split('~')\n",
    "        competency_ELO.at[i, 'group'] = gDict[key_split[0]]    \n",
    "        competency_ELO.at[i, 'user'] = key_split[0] \n",
    "        competency_ELO.at[i, 'task_id'] = key_split[1]\n",
    "        competency_ELO.at[i, 'kc'] = key_split[2]\n",
    "        # Normalized competency by kc\n",
    "        competency_ELO.at[i, 'final_kc_competency'] = round(normalized_learner_competency[key_split[0]][key_split[2]],3)\n",
    "        # Normalized average competency\n",
    "        competency_ELO.at[i, 'final_global_competency'] = round(normalized_global_competency[key_split[0]],3)\n",
    "        # Current competency\n",
    "        competency_ELO.at[i, 'current_competency'] = key_split[3]\n",
    "        # Probability\n",
    "        competency_ELO.at[i, 'probability'] = round(completedPartialData[i]['prob'],3)\n",
    "        # If the puzzle is completed\n",
    "        competency_ELO.at[i, 'correct'] = completedPartialData[i]['correct']\n",
    "        # KC weight\n",
    "        competency_ELO.at[i, 'kcs_importance'] = round(completedPartialData[i]['kcs importance'],3)\n",
    "        # Difficulty\n",
    "        competency_ELO.at[i, 'difficulty'] = key_split[4]\n",
    "        # Time stamp\n",
    "        competency_ELO.at[i, 'timestamp'] = completedPartialData[i]['timestamp']\n",
    "        # Update competency\n",
    "        competency_ELO.at[i, 'change_competency'] = round(completedPartialData[i]['changeComp'],3)\n",
    "        # Update difficulty\n",
    "        competency_ELO.at[i, 'change_difficulty'] = round(completedPartialData[i]['changeDiff'],3)\n",
    "           \n",
    "    #data output preparation  \n",
    "    difficulty_ELO = pd.DataFrame(difficulty_ELO, columns = ['group','task_id', 'difficulty'])\n",
    "    competency_ELO = pd.DataFrame(competency_ELO, columns = ['group','user','task_id', 'timestamp','kc','kcs_importance','final_kc_competency', 'final_global_competency','current_competency','change_competency', 'probability', 'correct', 'difficulty', 'change_difficulty'])\n",
    "    \n",
    "    return competency_ELO#, rmse, accuracy, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1. One Box': 269, '2. Separated Boxes': 259, '3. Rotate a Pyramid': 255, '4. Match Silhouettes': 252, 'Sugar Cones': 119, '8. Combine 2 Ramps': 201, '9. Scaling Round Objects': 195, 'Square Cross-Sections': 186, 'Bird Fez': 183, 'Pi Henge': 160, '45-Degree Rotations': 148, 'Pyramids are Strange': 152, 'Boxes Obscure Spheres': 164, 'Object Limits': 152, 'Tetromino': 11, 'Angled Silhouette': 122, 'Stranger Shapes': 128, 'Tall and Small': 100, '5. Removing Objects': 241, '6. Stretch a Ramp': 228, '7. Max 2 Boxes': 227, 'Ramp Up and Can It': 84, 'More Than Meets Your Eye': 78, 'Bear Market': 38, 'Not Bird': 91, 'Warm Up': 116, 'Unnecessary': 70, 'Zzz': 66, 'Bull Market': 54, 'Few Clues': 38, 'Orange Dance': 24}\n",
      "____\n",
      "{'953ea80f89aa793f2d8a17d212646301': 0.9545454545454546, '62201eb12dcba7f781f1f2e75482e1ef': 0.9375, 'bf0a784fe1efa01dc5a2e1ccd1f731fc': 0.8888888888888888, 'fb039fa921dd55d1b7eb210d8a5f75fc': 1.0, 'a86925711409ca9c76b1f1c1ef43d281': 1.0, 'cc9b0177c4af699f8c39c9f7126fa4a4': 1.0, 'dae8f18dec37209033af50bf2bc6722d': 0.9333333333333333, '4610cc6adb8b0aeea29d5eb053a8bcc5': 1.0, 'd4fa4c2c02058f0323918427c09248bf': 1.0, 'f5c577edc3b46150d0cbae675ee7e459': 1.0, 'f335e6139464347a152729767b7c10e6': 0.5, 'e71fff89938ec1fe219e736fa36f8b6b': 1.0, '2b0af0935243bf6aa00b6f7be5fdbabc': 1.0, 'be778b20fbbc034986feccd6f320585f': 0.9411764705882353, 'f22d5e004366e83c9eb106b13b21bc9d': 0.9565217391304348, 'f50c8d5d6414f0e64ef8c21973d0a6d6': 1.0, 'a6f176cf29c7a3e3bf3fc3c2362ac8c8': 1.0, '7efcb41a92a61b13280d8c19e2fef302': 1.0, '6ee4b916ed4b2366f0c521b3379f7960': 0.9629629629629629, '7a2c3ba5b630c18ff35177361c93141b': 1.0, '4cac6d6f0016fa63c459c4e9d0aa16b1': 1.0, 'f328f213fa502ed9b06a2f5f6ed88086': 1.0, '7ccdfc4cbcb4802bdc2b511f8d89eee3': 1.0, '0d35fa2868a21199e36b159b49ae6aad': 1.0, '1167e354a5b14bfe32706bdb0b67a0cf': 0.9655172413793104, '5e186eef80240c4069112f359dadf9ef': 1.0, 'b569f465acee475bc6eb06a288b823c7': 1.0, 'a139eff80ad1587e94570be61a28219e': 0.9130434782608695, '2636425489c6a77a532f75254d058a38': 0.8695652173913043, '4713ace1b155ff9642b1a0ed67c1fdf3': 0.8695652173913043, '031395e5e53450933d46c8646ae4ee27': 1.0, '1b55c999597635ddd855882330afecb8': 1.0, '2fc80637fca670560429037eb31234b6': 1.0, '8cec40ccb0fb360dd8828fa1d8843528': 1.0, '5d483abb3f27510378f2b7672e83bc1e': 0.875, 'ce2264a639e01f4ca75a0c242fbafb09': 0.5, 'f7ab47845da1e7938d6eacd273fff776': 1.0, '48e2fa8526344763b562fc7318987b5f': 0.6666666666666666, 'a9eac4d5476d2f20a263becdc89ca829': 0.6666666666666666, 'fb72fa38101a46d8857571aec0be9ce0': 1.0, '1295c9ddb112b1276f3967dad1b2ce7f': 1.0, 'b15f2a5087a673d4606ce6018525e7a0': 0.8571428571428571, 'd92de6cb8908be5916910148ab008b2c': 0.7857142857142857, '3ba430337eb30f5fd7569451b5dfdf32': 0.5384615384615384, 'a66f852274a441f4f9676b070c0c64db': 0.9047619047619048, '47813ad0c16e58f98f9c9b049195600b': 0.9, '2e473395015ae4d92006fd558776d59f': 0.6666666666666666, '3fdae469073e50e17048175c8e63de7d': 1.0, 'b268d12ce8397a934edad8c75983afdd': 0.9090909090909091, '27f08f1a1996a8fe6c46de7787676953': 1.0, '7ea1d408020c8831efec76c7554e5abf': 0.9333333333333333, 'c4374012b768c14df138b56f25018b58': 0.7727272727272727, 'fa5c548b7886cc9a4a03da68cb414905': 0.9090909090909091, '30bb014e5b15dd9fc656d307c2ac78af': 0.7, 'a2fa97f09291175fc3aa77a9749673d6': 1.0, '321e474105c67a79d3cbee73993c4af0': 0.875, '4ec219610dc2770a6877e012f1f4275f': 1.0, 'a5c3e0a06735be3f1c9f396c68be10a9': 1.0, 'caf081d70252877a1fdf2e72872355d0': 1.0, 'e38cbe491d2d84c6d4cdf2ed08e78d55': 1.0, '61826b2435a7a079a118b0a8473a4ffa': 1.0, '91e46c07c7105f932dadf5e732bdf1d0': 1.0, 'c396e31c6edc38e39218252ebc243b3c': 1.0, 'ea569ef5f2caa3294f865787d01bebfb': 1.0, 'ee9244078bab1b7e54aa21c9af7c9f69': 1.0, 'e7a1c28b6e31fa4ce644626262e21991': 1.0, 'f56eef88a0f83f726712b0fecbc81552': 1.0, 'ba915e03a3635bdb819f0e6d4000c5ca': 0.9166666666666666, '2828ad601746d2218f55b8ac4e94619d': 0.9, 'c107fca5bfaacfb2acdb4f696d639741': 1.0, 'a0b74e464805c9da87a54f1eb541ecf0': 1.0, '6fb3ff8d301777e350eebeb04ef58c4a': 0.8888888888888888, '6cc3178b47d20716422c1c3f2c5fe96b': 0.9090909090909091, '1870d7fdb0afbbdbc37c32e2a644239f': 1.0, '287866db18f943cf4cac87fc39e0eed2': 1.0, '6672e613399b164cbfe36519dfc71f07': 1.0, '30cc83a6a1f9f5d4331ee9b968e1b8f5': 1.0, 'f46a2482f35a0a401bf611fd85f4339d': 0.9411764705882353, 'f780fb1266b2137865259660adcf0b0a': 0.8, '7460c7ca07460c8b16f7b14aff5e4d8c': 1.0, '7be8b35ba9d4b1ad7c3d3f32b585df6f': 1.0, '270bf809fd1b7e871eebb0e6c39cb364': 1.0, 'c4e5c4626027530f46a81ff750f68b7f': 1.0, '520ea7a4dffdd14646427cb35cab5367': 1.0, '7e95e0d124f5d7852af4b05082db7b1c': 0.8947368421052632, 'eeb4ac2443dd0496ffbefa6780f4d7d4': 1.0, 'fb504c1409250aaef610c9d9b7306e18': 1.0, '5cce64bf55190c8816d80129f875b351': 1.0}\n"
     ]
    }
   ],
   "source": [
    "#competency_ELO = run('multiTopic',1.8, 0.05)\n",
    "acc_per_puzzle = run('metrics', 1.8, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7727272727272727"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.075"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8717948717948718"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
